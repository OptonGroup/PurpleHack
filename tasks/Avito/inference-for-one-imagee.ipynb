{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение цвета товара по фотографии\n",
    "\n",
    "## Предварительные требования (Prerequisites)\n",
    "\n",
    "Для запуска этого ноутбука требуются следующие зависимости:\n",
    "\n",
    "```\n",
    "Python >= 3.10\n",
    "numpy >= 1.24.3\n",
    "torch >= 2.0.1\n",
    "torchvision >= 0.15.2\n",
    "timm >= 0.9.7\n",
    "Pillow >= 10.0.0\n",
    "```\n",
    "\n",
    "Вы можете установить их с помощью pip:\n",
    "```bash\n",
    "pip install numpy torch torchvision timm Pillow\n",
    "```\n",
    "\n",
    "Перед использованием убедитесь, что у вас есть файл с весами модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "638e729e-b829-4491-bfa9-8427b6963fd8",
    "_uuid": "e6d78f08-eb6a-4b22-9bd9-794c50071429",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-14T01:13:58.449481Z",
     "iopub.status.busy": "2025-03-14T01:13:58.449171Z",
     "iopub.status.idle": "2025-03-14T01:13:58.465959Z",
     "shell.execute_reply": "2025-03-14T01:13:58.465182Z",
     "shell.execute_reply.started": "2025-03-14T01:13:58.449459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Словари соответствия\n",
    "TRANSLIT_TO_RU = {\n",
    "    'bezhevyi': 'бежевый',\n",
    "    'belyi': 'белый',\n",
    "    'biryuzovyi': 'бирюзовый',\n",
    "    'bordovyi': 'бордовый',\n",
    "    'goluboi': 'голубой',\n",
    "    'zheltyi': 'желтый',\n",
    "    'zelenyi': 'зеленый',\n",
    "    'zolotoi': 'золотой',\n",
    "    'korichnevyi': 'коричневый',\n",
    "    'krasnyi': 'красный',\n",
    "    'oranzhevyi': 'оранжевый',\n",
    "    'raznocvetnyi': 'разноцветный',\n",
    "    'rozovyi': 'розовый',\n",
    "    'serebristyi': 'серебряный',\n",
    "    'seryi': 'серый',\n",
    "    'sinii': 'синий',\n",
    "    'fioletovyi': 'фиолетовый',\n",
    "    'chernyi': 'черный'\n",
    "}\n",
    "\n",
    "# Создаем обратное соответствие с русского на транслитерацию\n",
    "RU_TO_TRANSLIT = {v: k for k, v in TRANSLIT_TO_RU.items()}\n",
    "\n",
    "# Словарь цветов\n",
    "COLORS = {\n",
    "    'бежевый': 'beige',\n",
    "    'белый': 'white',\n",
    "    'бирюзовый': 'turquoise',\n",
    "    'бордовый': 'burgundy',\n",
    "    'голубой': 'blue',\n",
    "    'желтый': 'yellow',\n",
    "    'зеленый': 'green',\n",
    "    'золотой': 'gold',\n",
    "    'коричневый': 'brown',\n",
    "    'красный': 'red',\n",
    "    'оранжевый': 'orange',\n",
    "    'разноцветный': 'variegated',\n",
    "    'розовый': 'pink',\n",
    "    'серебряный': 'silver',\n",
    "    'серый': 'gray',\n",
    "    'синий': 'blue',\n",
    "    'фиолетовый': 'purple',\n",
    "    'черный': 'black'\n",
    "}\n",
    "\n",
    "# Категории\n",
    "CATEGORIES = ['одежда для девочек', 'столы', 'стулья', 'сумки']\n",
    "\n",
    "# Глобальная переменная для хранения загруженной модели\n",
    "MODEL = None\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ColorClassifier(nn.Module):\n",
    "    def __init__(self, num_colors, num_categories):\n",
    "        super().__init__()\n",
    "        # Используем более легкий и быстрый вариант ViT\n",
    "        self.backbone = timm.create_model(\n",
    "            'beitv2_large_patch16_224', \n",
    "            pretrained=True, \n",
    "            num_classes=0,  # Без верхнего слоя классификации\n",
    "        )\n",
    "        \n",
    "        # Фиксируем большую часть весов для ускорения обучения\n",
    "        for param in list(self.backbone.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Расширение для быстрой инференции с кэшированием\n",
    "        self.backbone.reset_classifier(0)\n",
    "        \n",
    "        # Размерность признаков модели\n",
    "        self.feature_dim = self.backbone.embed_dim\n",
    "        \n",
    "        # Эмбеддинг категории\n",
    "        self.category_embedding = nn.Embedding(num_categories, 32)\n",
    "        \n",
    "        # Классификационная голова\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_colors)\n",
    "        )\n",
    "        \n",
    "        # Для оптимизации torch.jit\n",
    "        self.example_input = torch.zeros(1, 3, 224, 224)\n",
    "        self.example_category = torch.LongTensor([0])\n",
    "        \n",
    "    def forward(self, x, category):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        category_emb = self.category_embedding(category)\n",
    "        combined = torch.cat([features, category_emb], dim=1)\n",
    "        \n",
    "        return self.classifier(combined)\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Загружает ранее обученную модель из указанного пути.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    try:\n",
    "        # Пробуем загрузить как TorchScript модель\n",
    "        model = torch.jit.load(model_path, map_location=device)\n",
    "        print(\"Загружена оптимизированная TorchScript модель\")\n",
    "        return model\n",
    "    except:\n",
    "        # Загружаем как обычную модель\n",
    "        print(\"Загрузка модели из стандартных весов...\")\n",
    "        model = ColorClassifier(len(COLORS), len(CATEGORIES))\n",
    "        \n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        \n",
    "        # Установка модели в режим оценки\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        \n",
    "        return model\n",
    "\n",
    "def initialize_model(model_path=\"vit_color_classifier.pth\"):\n",
    "    \"\"\"\n",
    "    Инициализирует модель один раз и сохраняет её в глобальной переменной.\n",
    "    Эта функция должна быть вызвана один раз в начале вашего приложения.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Путь к весам модели\n",
    "        \n",
    "    Returns:\n",
    "        Загруженная модель\n",
    "    \"\"\"\n",
    "    global MODEL\n",
    "    if MODEL is None:\n",
    "        print(\"Загрузка модели в первый раз...\")\n",
    "        MODEL = load_model(model_path)\n",
    "    else:\n",
    "        print(\"Модель уже загружена, повторное использование...\")\n",
    "    \n",
    "    return MODEL\n",
    "\n",
    "def predict_color(image_path, category_name):\n",
    "    \"\"\"\n",
    "    Предсказывает цвет товара по изображению и его категории.\n",
    "    Использует глобально загруженную модель (убедитесь, что вызвали initialize_model сначала).\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Путь к изображению товара\n",
    "        category_name (str): Название категории товара (должно быть одним из CATEGORIES)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_color, top5_colors) где:\n",
    "            - best_color (str): Наиболее вероятный цвет в транслитерированной форме (например, 'bezhevyi')\n",
    "            - top5_colors (dict): Словарь с топ-5 цветами (в транслитерированной форме) и их вероятностями\n",
    "    \"\"\"\n",
    "    global MODEL, DEVICE\n",
    "    \n",
    "    # Проверяем, загружена ли модель\n",
    "    if MODEL is None:\n",
    "        raise RuntimeError(\"Модель не инициализирована. Пожалуйста, вызовите initialize_model() сначала.\")\n",
    "    \n",
    "    # Проверяем название категории\n",
    "    if category_name not in CATEGORIES:\n",
    "        raise ValueError(f\"Категория должна быть одной из: {CATEGORIES}\")\n",
    "    \n",
    "    # Проверяем существование изображения\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Изображение не найдено: {image_path}\")\n",
    "    \n",
    "    # Подготавливаем трансформацию изображения\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    # Загружаем и трансформируем изображение\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_tensor = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Ошибка при обработке изображения: {str(e)}\")\n",
    "    \n",
    "    # Получаем индекс категории\n",
    "    category_idx = CATEGORIES.index(category_name)\n",
    "    category_tensor = torch.tensor([category_idx], dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    # Делаем предсказание\n",
    "    with torch.no_grad():\n",
    "        outputs = MODEL(image_tensor, category_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    # Получаем названия цветов на русском\n",
    "    color_list = list(COLORS.keys())\n",
    "    \n",
    "    # Находим лучший цвет\n",
    "    best_color_idx = np.argmax(probs)\n",
    "    best_color_ru = color_list[best_color_idx]\n",
    "    \n",
    "    # Преобразуем в транслитерированную форму\n",
    "    best_color = RU_TO_TRANSLIT[best_color_ru]\n",
    "    \n",
    "    # Получаем топ-5 цветов с вероятностями\n",
    "    top5_indices = np.argsort(probs)[-5:][::-1]\n",
    "    \n",
    "    # Преобразуем цвета в транслитерированную форму в результате\n",
    "    top5_colors = {RU_TO_TRANSLIT[color_list[idx]]: float(probs[idx]) for idx in top5_indices}\n",
    "    \n",
    "    return best_color, top5_colors\n",
    "\n",
    "# Пример использования:\n",
    "# 1. Инициализируем модель один раз в начале\n",
    "# model = initialize_model(\"vit_color_classifier.pth\")\n",
    "#\n",
    "# 2. Делаем предсказания столько раз, сколько нужно, без повторной загрузки модели\n",
    "# best_color, top5_colors = predict_color(\"path/to/image.jpg\", \"столы\")\n",
    "# print(f\"Наиболее вероятный цвет: {best_color}\")\n",
    "# for color, prob in top5_colors.items():\n",
    "#     print(f\"  {color}: {prob:.4f}\")\n",
    "#\n",
    "# 3. Делаем еще одно предсказание с той же моделью\n",
    "# best_color2, top5_colors2 = predict_color(\"path/to/another_image.jpg\", \"стулья\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T01:14:17.475880Z",
     "iopub.status.busy": "2025-03-14T01:14:17.475514Z",
     "iopub.status.idle": "2025-03-14T01:14:24.078098Z",
     "shell.execute_reply": "2025-03-14T01:14:24.077400Z",
     "shell.execute_reply.started": "2025-03-14T01:14:17.475838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for the first time...\n",
      "Loading model from standard weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-c8fbc8292a2c>:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(\"/kaggle/input/macro_/pytorch/default/1/macro_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T01:14:29.701039Z",
     "iopub.status.busy": "2025-03-14T01:14:29.700745Z",
     "iopub.status.idle": "2025-03-14T01:14:29.801529Z",
     "shell.execute_reply": "2025-03-14T01:14:29.800854Z",
     "shell.execute_reply.started": "2025-03-14T01:14:29.701017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best color: zelenyi\n",
      "Top 5 colors:\n",
      "  zelenyi: 0.9715\n",
      "  chernyi: 0.0067\n",
      "  raznocvetnyi: 0.0044\n",
      "  korichnevyi: 0.0040\n",
      "  sinii: 0.0034\n"
     ]
    }
   ],
   "source": [
    "best_color, top5_colors = predict_color(\"/kaggle/input/colors/dataset_colors/test_data/19762915377.png\", \"одежда для девочек\")\n",
    "print(f\"Наиболее вероятный цвет: {best_color}\")  # Теперь возвращает 'bezhevyi' вместо 'бежевый'\n",
    "print(\"Топ-5 цветов:\")\n",
    "for color, prob in top5_colors.items():\n",
    "    print(f\"  {color}: {prob:.4f}\")  # Цвета теперь в транслитерированной форме\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерактивный пример\n",
    "\n",
    "Ниже вы можете ввести путь к вашему изображению и выбрать категорию товара для определения его цвета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Интерактивный ввод для тестирования на произвольных изображениях\n",
    "image_path = input(\"Введите путь к изображению: \")\n",
    "print(\"Доступные категории:\")\n",
    "for i, category in enumerate(CATEGORIES):\n",
    "    print(f\"{i+1}. {category}\")\n",
    "category_idx = int(input(\"Выберите номер категории (1-4): \")) - 1\n",
    "\n",
    "if 0 <= category_idx < len(CATEGORIES):\n",
    "    category = CATEGORIES[category_idx]\n",
    "    best_color, top5_colors = predict_color(image_path, category)\n",
    "    \n",
    "    print(f\"\\nНаиболее вероятный цвет: {TRANSLIT_TO_RU[best_color]}\")\n",
    "    print(\"Топ-5 цветов:\")\n",
    "    for color, prob in top5_colors.items():\n",
    "        print(f\"  {TRANSLIT_TO_RU[color]}: {prob:.4f}\")\n",
    "else:\n",
    "    print(\"Неверный номер категории.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6820041,
     "sourceId": 10962139,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 266217,
     "modelInstanceId": 244595,
     "sourceId": 285395,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
