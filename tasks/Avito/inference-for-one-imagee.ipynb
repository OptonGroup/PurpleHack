{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10962139,"sourceType":"datasetVersion","datasetId":6820041},{"sourceId":285395,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":244595,"modelId":266217}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom PIL import Image\nimport timm\nimport torchvision.transforms as transforms\n\n# Mapping dictionaries\nTRANSLIT_TO_RU = {\n    'bezhevyi': 'бежевый',\n    'belyi': 'белый',\n    'biryuzovyi': 'бирюзовый',\n    'bordovyi': 'бордовый',\n    'goluboi': 'голубой',\n    'zheltyi': 'желтый',\n    'zelenyi': 'зеленый',\n    'zolotoi': 'золотой',\n    'korichnevyi': 'коричневый',\n    'krasnyi': 'красный',\n    'oranzhevyi': 'оранжевый',\n    'raznocvetnyi': 'разноцветный',\n    'rozovyi': 'розовый',\n    'serebristyi': 'серебряный',\n    'seryi': 'серый',\n    'sinii': 'синий',\n    'fioletovyi': 'фиолетовый',\n    'chernyi': 'черный'\n}\n\n# Create reverse mapping from Russian to transliteration\nRU_TO_TRANSLIT = {v: k for k, v in TRANSLIT_TO_RU.items()}\n\n# Colors dictionary\nCOLORS = {\n    'бежевый': 'beige',\n    'белый': 'white',\n    'бирюзовый': 'turquoise',\n    'бордовый': 'burgundy',\n    'голубой': 'blue',\n    'желтый': 'yellow',\n    'зеленый': 'green',\n    'золотой': 'gold',\n    'коричневый': 'brown',\n    'красный': 'red',\n    'оранжевый': 'orange',\n    'разноцветный': 'variegated',\n    'розовый': 'pink',\n    'серебряный': 'silver',\n    'серый': 'gray',\n    'синий': 'blue',\n    'фиолетовый': 'purple',\n    'черный': 'black'\n}\n\n# Categories\nCATEGORIES = ['одежда для девочек', 'столы', 'стулья', 'сумки']\n\n# Global variable to store the loaded model\nMODEL = None\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass ColorClassifier(nn.Module):\n    def __init__(self, num_colors, num_categories):\n        super().__init__()\n        # Using a lighter and faster ViT variant\n        self.backbone = timm.create_model(\n            'beitv2_large_patch16_224', \n            pretrained=True, \n            num_classes=0,  # Without top classification layer\n        )\n        \n        # Fixed most weights to speed up training\n        for param in list(self.backbone.parameters())[:-30]:\n            param.requires_grad = False\n            \n        # Extension for fast inference with caching\n        self.backbone.reset_classifier(0)\n        \n        # Model feature dimension\n        self.feature_dim = self.backbone.embed_dim\n        \n        # Category embedding\n        self.category_embedding = nn.Embedding(num_categories, 32)\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(self.feature_dim + 32, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_colors)\n        )\n        \n        # For torch.jit optimization\n        self.example_input = torch.zeros(1, 3, 224, 224)\n        self.example_category = torch.LongTensor([0])\n        \n    def forward(self, x, category):\n        features = self.backbone(x)\n        \n        category_emb = self.category_embedding(category)\n        combined = torch.cat([features, category_emb], dim=1)\n        \n        return self.classifier(combined)\n\ndef load_model(model_path):\n    \"\"\"\n    Loads a previously trained model from the specified path.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    try:\n        # Try to load as a TorchScript model\n        model = torch.jit.load(model_path, map_location=device)\n        print(\"Loaded optimized TorchScript model\")\n        return model\n    except:\n        # Load as a regular model\n        print(\"Loading model from standard weights...\")\n        model = ColorClassifier(len(COLORS), len(CATEGORIES))\n        \n        checkpoint = torch.load(model_path, map_location=device)\n        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n            model.load_state_dict(checkpoint['model_state_dict'])\n        else:\n            model.load_state_dict(checkpoint)\n        \n        # Set model to evaluation mode\n        model.eval()\n        model = model.to(device)\n        \n        return model\n\ndef initialize_model(model_path=\"vit_color_classifier.pth\"):\n    \"\"\"\n    Initialize the model once and store it in a global variable.\n    This function should be called once at the beginning of your application.\n    \n    Args:\n        model_path (str): Path to the model weights\n        \n    Returns:\n        The loaded model\n    \"\"\"\n    global MODEL\n    if MODEL is None:\n        print(\"Loading model for the first time...\")\n        MODEL = load_model(model_path)\n    else:\n        print(\"Model already loaded, reusing...\")\n    \n    return MODEL\n\ndef predict_color(image_path, category_name):\n    \"\"\"\n    Predicts the color of a product from an image and its category.\n    Uses the globally loaded model (make sure to call initialize_model first).\n    \n    Args:\n        image_path (str): Path to the product image\n        category_name (str): Category name of the product (must be one of CATEGORIES)\n        \n    Returns:\n        tuple: (best_color, top5_colors) where:\n            - best_color (str): The most likely color in transliterated form (e.g. 'bezhevyi')\n            - top5_colors (dict): Dictionary with top 5 colors (in transliterated form) and their probabilities\n    \"\"\"\n    global MODEL, DEVICE\n    \n    # Check if model is loaded\n    if MODEL is None:\n        raise RuntimeError(\"Model not initialized. Please call initialize_model() first.\")\n    \n    # Validate category name\n    if category_name not in CATEGORIES:\n        raise ValueError(f\"Category must be one of: {CATEGORIES}\")\n    \n    # Check if image exists\n    if not os.path.exists(image_path):\n        raise FileNotFoundError(f\"Image not found: {image_path}\")\n    \n    # Prepare image transformation\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    \n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    \n    # Load and transform the image\n    try:\n        image = Image.open(image_path).convert('RGB')\n        image_tensor = transform(image).unsqueeze(0).to(DEVICE)\n    except Exception as e:\n        raise RuntimeError(f\"Error processing image: {str(e)}\")\n    \n    # Get category index\n    category_idx = CATEGORIES.index(category_name)\n    category_tensor = torch.tensor([category_idx], dtype=torch.long).to(DEVICE)\n    \n    # Make prediction\n    with torch.no_grad():\n        outputs = MODEL(image_tensor, category_tensor)\n        probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n    \n    # Get the color names in Russian\n    color_list = list(COLORS.keys())\n    \n    # Find the best color\n    best_color_idx = np.argmax(probs)\n    best_color_ru = color_list[best_color_idx]\n    \n    # Convert to transliterated form\n    best_color = RU_TO_TRANSLIT[best_color_ru]\n    \n    # Get top 5 colors with probabilities\n    top5_indices = np.argsort(probs)[-5:][::-1]\n    \n    # Convert colors to transliterated form in the result\n    top5_colors = {RU_TO_TRANSLIT[color_list[idx]]: float(probs[idx]) for idx in top5_indices}\n    \n    return best_color, top5_colors\n\n# Example usage:\n# 1. Initialize the model once at the beginning\n# model = initialize_model(\"vit_color_classifier.pth\")\n#\n# 2. Make predictions as many times as needed without reloading the model\n# best_color, top5_colors = predict_color(\"path/to/image.jpg\", \"столы\")\n# print(f\"Best color: {best_color}\")\n# for color, prob in top5_colors.items():\n#     print(f\"  {color}: {prob:.4f}\")\n#\n# 3. Make another prediction with the same model\n# best_color2, top5_colors2 = predict_color(\"path/to/another_image.jpg\", \"стулья\")\n","metadata":{"_uuid":"e6d78f08-eb6a-4b22-9bd9-794c50071429","_cell_guid":"638e729e-b829-4491-bfa9-8427b6963fd8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-14T01:13:58.449171Z","iopub.execute_input":"2025-03-14T01:13:58.449481Z","iopub.status.idle":"2025-03-14T01:13:58.465959Z","shell.execute_reply.started":"2025-03-14T01:13:58.449459Z","shell.execute_reply":"2025-03-14T01:13:58.465182Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model = initialize_model(\"/kaggle/input/macro_/pytorch/default/1/macro_weights.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T01:14:17.475514Z","iopub.execute_input":"2025-03-14T01:14:17.475880Z","iopub.status.idle":"2025-03-14T01:14:24.078098Z","shell.execute_reply.started":"2025-03-14T01:14:17.475838Z","shell.execute_reply":"2025-03-14T01:14:24.077400Z"}},"outputs":[{"name":"stdout","text":"Loading model for the first time...\nLoading model from standard weights...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-3-c8fbc8292a2c>:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(model_path, map_location=device)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"best_color, top5_colors = predict_color(\"/kaggle/input/colors/dataset_colors/test_data/19762915377.png\", \"одежда для девочек\")\nprint(f\"Best color: {best_color}\")  # Now returns 'bezhevyi' instead of 'бежевый'\nprint(\"Top 5 colors:\")\nfor color, prob in top5_colors.items():\n    print(f\"  {color}: {prob:.4f}\")  # Colors are now in transliterated form\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T01:14:29.700745Z","iopub.execute_input":"2025-03-14T01:14:29.701039Z","iopub.status.idle":"2025-03-14T01:14:29.801529Z","shell.execute_reply.started":"2025-03-14T01:14:29.701017Z","shell.execute_reply":"2025-03-14T01:14:29.800854Z"}},"outputs":[{"name":"stdout","text":"Best color: zelenyi\nTop 5 colors:\n  zelenyi: 0.9715\n  chernyi: 0.0067\n  raznocvetnyi: 0.0044\n  korichnevyi: 0.0040\n  sinii: 0.0034\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}