{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10962139,"sourceType":"datasetVersion","datasetId":6820041},{"sourceId":285395,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":244595,"modelId":266217}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport json\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport torchvision.transforms.functional as F\nimport random\ntry:\n    import timm  # Добавим библиотеку timm для эффективных моделей\nexcept ImportError:\n    import subprocess\n    subprocess.check_call([\"pip\", \"install\", \"timm\"])\n    import timm\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\nfrom tqdm import tqdm\nimport copy\nimport time\nimport timm  # Добавим библиотеку timm для эффективных моделей","metadata":{"_uuid":"f9f1bdcf-985f-43b3-9648-5293bb15a34c","_cell_guid":"035b50af-9d8f-48a4-9d37-6a0e3894556c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-14T02:21:36.769824Z","iopub.execute_input":"2025-03-14T02:21:36.770203Z","iopub.status.idle":"2025-03-14T02:21:36.775872Z","shell.execute_reply.started":"2025-03-14T02:21:36.770172Z","shell.execute_reply":"2025-03-14T02:21:36.775192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Определение путей к данным\n# CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\nDATA_DIR = '/kaggle/input/colors/dataset_colors'\nTRAIN_DATA_DIR = '/kaggle/input/colors/dataset_colors/train_data'\nTEST_DATA_DIR = '/kaggle/input/colors/dataset_colors/test_data'\nTRAIN_CSV = '/kaggle/input/colors/dataset_colors/train_data.csv'\nTEST_CSV = '/kaggle/input/colors/dataset_colors/test_data.csv'","metadata":{"_uuid":"5ff3bd8a-f811-444a-b06c-8732831d1734","_cell_guid":"864956b3-2531-4a7e-9c9f-031549ed35b2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:36.976071Z","iopub.execute_input":"2025-03-14T02:21:36.976311Z","iopub.status.idle":"2025-03-14T02:21:36.980313Z","shell.execute_reply.started":"2025-03-14T02:21:36.976293Z","shell.execute_reply":"2025-03-14T02:21:36.979577Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRANSLIT_TO_RU = {\n    'bezhevyi': 'бежевый',\n    'belyi': 'белый',\n    'biryuzovyi': 'бирюзовый',\n    'bordovyi': 'бордовый',\n    'goluboi': 'голубой',\n    'zheltyi': 'желтый',\n    'zelenyi': 'зеленый',\n    'zolotoi': 'золотой',\n    'korichnevyi': 'коричневый',\n    'krasnyi': 'красный',\n    'oranzhevyi': 'оранжевый',\n    'raznocvetnyi': 'разноцветный',\n    'rozovyi': 'розовый',\n    'serebristyi': 'серебряный',\n    'seryi': 'серый',\n    'sinii': 'синий',\n    'fioletovyi': 'фиолетовый',\n    'chernyi': 'черный'\n}\n\n# Создаем обратный маппинг с русского на транслит\nRU_TO_TRANSLIT = {v: k for k, v in TRANSLIT_TO_RU.items()}","metadata":{"_uuid":"e3e6ae0f-d3b0-462e-a48f-1c734318b5c2","_cell_guid":"1363ff4c-1d48-4531-b916-d77d11150e57","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:37.107464Z","iopub.execute_input":"2025-03-14T02:21:37.107743Z","iopub.status.idle":"2025-03-14T02:21:37.112683Z","shell.execute_reply.started":"2025-03-14T02:21:37.107720Z","shell.execute_reply":"2025-03-14T02:21:37.111966Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Маппинг цветов\nCOLORS = {\n    'бежевый': 'beige',\n    'белый': 'white',\n    'бирюзовый': 'turquoise',\n    'бордовый': 'burgundy',\n    'голубой': 'blue',\n    'желтый': 'yellow',\n    'зеленый': 'green',\n    'золотой': 'gold',\n    'коричневый': 'brown',\n    'красный': 'red',\n    'оранжевый': 'orange',\n    'разноцветный': 'variegated',\n    'розовый': 'pink',\n    'серебряный': 'silver',\n    'серый': 'gray',\n    'синий': 'blue',\n    'фиолетовый': 'purple',\n    'черный': 'black'\n}\n\n# Создаем обратный словарь для получения индекса по цвету\nCOLOR_INDICES = {c: i for i, c in enumerate(COLORS.keys())}\n\nCATEGORIES = ['одежда для девочек', 'столы', 'стулья', 'сумки']","metadata":{"_uuid":"95308eeb-ef31-46be-ac74-5522a3d6759d","_cell_guid":"c4b998a8-2ed3-49b8-b401-2120446d2f0e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:37.234855Z","iopub.execute_input":"2025-03-14T02:21:37.235116Z","iopub.status.idle":"2025-03-14T02:21:37.239744Z","shell.execute_reply.started":"2025-03-14T02:21:37.235096Z","shell.execute_reply":"2025-03-14T02:21:37.238949Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ProductDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_test=False):\n        self.df = df.reset_index(drop=True)  # Сбрасываем индексы после фильтрации\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.category_to_idx = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n        self.color_to_idx = {color: idx for idx, color in enumerate(COLORS.keys())}\n        \n        # Проверяем все пути к изображениям заранее\n        self.valid_indices = []\n        \n        # Если в датафрейме есть путь к изображению, используем его\n        if 'image_path' in self.df.columns:\n            for idx in range(len(df)):\n                if pd.notna(self.df.iloc[idx]['image_path']):\n                    # Проверяем, что файл действительно существует\n                    img_path = self.df.iloc[idx]['image_path']\n                    if os.path.exists(img_path):\n                        self.valid_indices.append(idx)\n                    else:\n                        print(f\"Предупреждение: файл {img_path} не существует\")\n                else:\n                    # Пробуем найти файл с разными расширениями\n                    img_id = df.iloc[idx]['id']\n                    extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n                    found = False\n                    \n                    for ext in extensions:\n                        img_path = os.path.join(self.img_dir, f\"{img_id}{ext}\")\n                        if os.path.exists(img_path):\n                            self.df.at[idx, 'image_path'] = img_path\n                            self.valid_indices.append(idx)\n                            found = True\n                            break\n                    \n                    if not found:\n                        print(f\"Не найдено изображение для id: {img_id}\")\n        else:\n            # Проверяем разные расширения файлов\n            for idx in range(len(df)):\n                found = False\n                img_id = df.iloc[idx]['id']\n                extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n                \n                for ext in extensions:\n                    img_path = os.path.join(self.img_dir, f\"{img_id}{ext}\")\n                    if os.path.exists(img_path):\n                        found = True\n                        break\n                \n                if found:\n                    self.valid_indices.append(idx)\n                else:\n                    print(f\"Не найдено изображение для id: {img_id}\")\n        \n        # Выводим первые 5 и последние 5 индексов для проверки\n        if len(self.valid_indices) > 0:\n            print(f\"Первые 5 валидных индексов: {self.valid_indices[:5]}\")\n            if len(self.valid_indices) > 5:\n                print(f\"Последние 5 валидных индексов: {self.valid_indices[-5:]}\")\n            \n            # Вывод путей для проверки\n            for i in range(min(5, len(self.valid_indices))):\n                idx = self.valid_indices[i]\n                img_id = self.df.iloc[idx]['id']\n                if 'image_path' in self.df.columns and pd.notna(self.df.iloc[idx]['image_path']):\n                    print(f\"ID: {img_id}, путь: {self.df.iloc[idx]['image_path']}\")\n                else:\n                    print(f\"ID: {img_id}, путь не сохранен\")\n        \n        if len(self.valid_indices) == 0:\n            # Дополнительная отладочная информация\n            print(f\"Проверяем доступность директории: {img_dir}, существует: {os.path.exists(img_dir)}\")\n            if os.path.exists(img_dir):\n                # Вывести список файлов в директории\n                files = os.listdir(img_dir)\n                print(f\"Первые 10 файлов в директории: {files[:10] if len(files) > 0 else 'директория пуста'}\")\n                \n                # Проверка первых 5 записей датафрейма\n                for idx in range(min(5, len(df))):\n                    img_id = df.iloc[idx]['id']\n                    print(f\"Проверка ID: {img_id}\")\n                    for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n                        img_path = os.path.join(img_dir, f\"{img_id}{ext}\")\n                        print(f\"  Путь {img_path} существует: {os.path.exists(img_path)}\")\n            \n            raise ValueError(f\"Не найдено ни одного изображения в директории {img_dir}\")\n        \n        print(f\"Найдено {len(self.valid_indices)} валидных изображений из {len(df)}\")\n        \n    def __len__(self):\n        return len(self.valid_indices)\n    \n    def __getitem__(self, idx):\n        real_idx = self.valid_indices[idx]\n        img_id = self.df.iloc[real_idx]['id']\n        \n        # Используем сохраненный путь если он есть, иначе ищем файл\n        if 'image_path' in self.df.columns and pd.notna(self.df.iloc[real_idx]['image_path']):\n            img_path = self.df.iloc[real_idx]['image_path']\n        else:\n            # Проверяем разные расширения файлов\n            extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n            img_path = None\n            \n            for ext in extensions:\n                path = os.path.join(self.img_dir, f\"{img_id}{ext}\")\n                if os.path.exists(path):\n                    img_path = path\n                    break\n                    \n            if img_path is None:\n                # Если не найдено, используем стандартный путь (вызовет ошибку при отсутствии файла)\n                img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n        except Exception as e:\n            print(f\"Ошибка при загрузке изображения {img_path}: {str(e)}\")\n            raise\n        \n        if self.transform:\n            try:\n                image = self.transform(image)\n            except Exception as e:\n                print(f\"Ошибка при применении трансформации к {img_path}: {str(e)}\")\n                raise\n            \n        category = self.category_to_idx[self.df.iloc[real_idx]['category']]\n        \n        if not self.is_test:\n            color_translit = self.df.iloc[real_idx]['target']\n            color_ru = TRANSLIT_TO_RU[color_translit]\n            color = self.color_to_idx[color_ru]\n            return image, category, color\n        \n        return image, category, img_id","metadata":{"_uuid":"b35de827-1e6c-4e96-8610-39ac0d2b49ef","_cell_guid":"9413d17b-f117-4d3c-99cb-4dc0b87f99cb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:37.369755Z","iopub.execute_input":"2025-03-14T02:21:37.370006Z","iopub.status.idle":"2025-03-14T02:21:37.387046Z","shell.execute_reply.started":"2025-03-14T02:21:37.369987Z","shell.execute_reply":"2025-03-14T02:21:37.386189Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ColorClassifier(nn.Module):\n    def __init__(self, num_colors, num_categories):\n        super().__init__()\n        # Используем более легкий и быстрый вариант ViT\n        self.backbone = timm.create_model(\n            'beitv2_large_patch16_224', \n            pretrained=True, \n            num_classes=0,  # Без верхнего слоя классификации\n        )\n        \n        # Фиксируем большую часть весов для ускорения обучения\n        for param in list(self.backbone.parameters())[:-30]:\n            param.requires_grad = False\n            \n        # Расширение для быстрой инференции с помощью кэширования\n        self.backbone.reset_classifier(0)\n        \n        # Размерность характеристик модели\n        self.feature_dim = self.backbone.embed_dim  # Для vit_tiny это 192\n        \n        # Эмбеддинг категории\n        self.category_embedding = nn.Embedding(num_categories, 32)\n        \n        # Классификационная голова\n        self.classifier = nn.Sequential(\n            nn.Linear(self.feature_dim + 32, 256),  # Меньше параметров для ускорения\n            nn.ReLU(),\n            nn.Dropout(0.2),  # Меньше дропаут для более быстрой сходимости\n            nn.Linear(256, num_colors)\n        )\n        \n        # Для оптимизации torch.jit\n        self.example_input = torch.zeros(1, 3, 224, 224)\n        self.example_category = torch.LongTensor([0])\n        \n    def forward(self, x, category):\n        features = self.backbone(x)\n        \n        category_emb = self.category_embedding(category)\n        combined = torch.cat([features, category_emb], dim=1)\n        \n        return self.classifier(combined)\n\n    def optimize_for_inference(self, device):\n        \"\"\"Оптимизирует модель для быстрой инференции\"\"\"\n        self.eval()\n        # Использование TorchScript для оптимизации\n        return torch.jit.trace((self.example_input.to(device), self.example_category.to(device)), self)","metadata":{"_uuid":"d9bc1d2c-6fcc-405b-9526-9458027acd44","_cell_guid":"4081521b-11ca-477a-8e9e-fd01736a2fea","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:37.489248Z","iopub.execute_input":"2025-03-14T02:21:37.489470Z","iopub.status.idle":"2025-03-14T02:21:37.495840Z","shell.execute_reply.started":"2025-03-14T02:21:37.489453Z","shell.execute_reply":"2025-03-14T02:21:37.495178Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(model_path):\n    \"\"\"\n    Загружает ранее обученную модель из указанного пути.\n    Если модель была сохранена как TorchScript, загрузит её как таковую.\n    Функция вызывается только один раз.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Проверяем формат сохраненной модели\n    try:\n        # Пробуем загрузить как TorchScript модель\n        model = torch.jit.load(model_path, map_location=device)\n        print(\"Загружена оптимизированная TorchScript модель\")\n        return model\n    except:\n        # Загружаем как обычную модель\n        print(\"Загружаем модель из стандартных весов...\")\n        model = ColorClassifier(len(COLORS), len(CATEGORIES))\n        \n        checkpoint = torch.load(model_path, map_location=device)\n        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n            model.load_state_dict(checkpoint['model_state_dict'])\n        else:\n            model.load_state_dict(checkpoint)\n        \n        # Установка модели в режим оценки (инференса)\n        model.eval()\n        \n        model = model.to(device)\n        \n        return model","metadata":{"_uuid":"90951210-c8bb-4f7d-aa80-6744f8dba6c1","_cell_guid":"8c35fc51-64e7-42ab-b0ca-9222916f352e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:37.620953Z","iopub.execute_input":"2025-03-14T02:21:37.621183Z","iopub.status.idle":"2025-03-14T02:21:37.626480Z","shell.execute_reply.started":"2025-03-14T02:21:37.621164Z","shell.execute_reply":"2025-03-14T02:21:37.625677Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(model, test_loader, seed=42, use_transliteration=True):\n    \"\"\"\n    Запускает модель на тестовом датасете и возвращает предсказания.\n    \n    Args:\n        model: Обученная модель\n        test_loader: DataLoader с тестовыми данными\n        seed: Seed для воспроизводимости\n        use_transliteration: Если True, возвращает цвета в транслитерации\n        \n    Returns:\n        DataFrame с предсказаниями\n    \"\"\"\n    # Устанавливаем сид для воспроизводимости\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Используется устройство: {device}\")\n    \n    model = model.to(device)\n    model.eval()\n    \n    predictions = []\n    \n    # Получаем список цветов\n    color_list = list(COLORS.keys())\n    \n    # Замер времени на один батч\n    batch_times = []\n    \n    with torch.no_grad():\n        for images, categories, img_ids in tqdm(test_loader, desc=\"Инференс\"):\n            images = images.to(device)\n            categories = categories.to(device)\n            \n            # Замер времени\n            start_time = time.time()\n            outputs = model(images, categories)\n            end_time = time.time()\n            \n            inference_time = (end_time - start_time) * 1000  # мс\n            batch_times.append(inference_time / len(images))  # время на один образец\n            \n            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n            \n            for img_id, category_idx, prob in zip(img_ids, categories.cpu().numpy(), probs):\n                # Преобразуем id из тензора в обычное значение\n                if isinstance(img_id, torch.Tensor):\n                    img_id = img_id.item()  # для числовых id\n                # Если id является строкой в тензоре:\n                elif hasattr(img_id, 'item') and not isinstance(img_id, (int, float, str)):\n                    img_id = str(img_id)\n                \n                # Получаем категорию товара\n                category = CATEGORIES[category_idx]\n                \n                # Формируем словарь вероятностей для каждого цвета\n                if use_transliteration:\n                    # Используем транслитерацию для ключей словаря\n                    pred_dict = {RU_TO_TRANSLIT[color]: float(p) for color, p in zip(color_list, prob)}\n                    # Определяем цвет с максимальной вероятностью\n                    pred_color = RU_TO_TRANSLIT[color_list[np.argmax(prob)]]\n                else:\n                    # Используем русские названия цветов\n                    pred_dict = {color: float(p) for color, p in zip(color_list, prob)}\n                    pred_color = color_list[np.argmax(prob)]\n                \n                predictions.append({\n                    'id': img_id,\n                    'category': category,\n                    'predict_proba': json.dumps(pred_dict),\n                    'predict_color': pred_color\n                })\n                \n    # Вывод среднего времени инференции\n    if batch_times:\n        avg_time = sum(batch_times) / len(batch_times)\n        print(f\"Среднее время инференции на одно изображение: {avg_time:.2f} мс\")\n    \n    # Создаем DataFrame с предсказаниями\n    predictions_df = pd.DataFrame(predictions)\n    return predictions_df","metadata":{"_uuid":"2fc4dfcb-4ab8-47af-ad0d-5c413a520df5","_cell_guid":"e18417b7-bd79-4ef0-a52d-7d3466b6f044","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:37.754301Z","iopub.execute_input":"2025-03-14T02:21:37.754532Z","iopub.status.idle":"2025-03-14T02:21:37.763436Z","shell.execute_reply.started":"2025-03-14T02:21:37.754515Z","shell.execute_reply":"2025-03-14T02:21:37.762746Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_test_dataset(test_df, model_path, test_data_dir=TEST_DATA_DIR, seed=42):\n    \"\"\"\n    Функция для предсказания цветов на тестовом датасете.\n    \n    Args:\n        test_df: DataFrame с тестовыми данными\n        model_path: Путь к сохраненной модели\n        test_data_dir: Директория с тестовыми изображениями\n        seed: Seed для воспроизводимости\n    \n    Returns:\n        DataFrame с предсказаниями в требуемом формате\n    \"\"\"\n    # Устанавливаем сид для воспроизводимости\n    set_seed(seed)\n    \n    # Загружаем модель\n    model = load_model(model_path)\n    \n    # Проверяем наличие каталога с тестовыми данными\n    if not os.path.exists(test_data_dir):\n        print(f\"Предупреждение: директория {test_data_dir} не существует!\")\n        # Попробуем найти правильный путь\n        parent_dir = os.path.dirname(test_data_dir)\n        if os.path.exists(parent_dir):\n            subdirs = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]\n            print(f\"Доступные подкаталоги в {parent_dir}: {subdirs}\")\n    else:\n        # Вывести первые несколько файлов для проверки\n        files = os.listdir(test_data_dir)\n        print(f\"Найдено {len(files)} файлов в {test_data_dir}\")\n        print(f\"Примеры файлов: {files[:5] if files else 'директория пуста'}\")\n    \n    # Проверяем наличие файлов изображений с разными расширениями\n    def check_image_exists(row, data_dir):\n        # Проверяем разные расширения файлов\n        extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n        img_id = row['id']\n        \n        for ext in extensions:\n            img_path = os.path.join(data_dir, f\"{img_id}{ext}\")\n            if os.path.exists(img_path):\n                # Сохраняем найденный путь в строке датафрейма для дальнейшего использования\n                row['image_path'] = img_path\n                return True\n        \n        # Дополнительная проверка на случай, если файл существует без расширения\n        img_path = os.path.join(data_dir, f\"{img_id}\")\n        if os.path.exists(img_path):\n            row['image_path'] = img_path\n            return True\n            \n        # Пробуем найти файл с этим ID без полного совпадения\n        for file in os.listdir(data_dir):\n            if file.startswith(str(img_id)):\n                img_path = os.path.join(data_dir, file)\n                row['image_path'] = img_path\n                print(f\"Найден файл по частичному совпадению: {img_path}\")\n                return True\n        \n        # Выводим предупреждение только для первых 10 ненайденных файлов\n        if row.name < 10:\n            print(f\"Не найдено изображение для id: {img_id}\")\n        elif row.name == 10:\n            print(\"... и для других ID (не выводится для экономии места)\")\n        return False\n    \n    # Добавляем столбец для хранения пути к изображению\n    test_df['image_path'] = None\n    \n    # Применяем фильтрацию и сохраняем найденные пути к изображениям\n    valid_rows = test_df.apply(lambda row: check_image_exists(row, test_data_dir), axis=1)\n    \n    # Выводим количество найденных путей\n    valid_count = valid_rows.sum()\n    print(f\"Найдено {valid_count} файлов изображений из {len(test_df)}\")\n    \n    if valid_count == 0:\n        print(\"Не удалось найти ни одного файла изображения! Проверьте пути к данным.\")\n        # Вместо фильтрации, сохраним все строки и заполним пути заглушками для отладки\n        for idx in range(len(test_df)):\n            test_df.at[idx, 'image_path'] = os.path.join(test_data_dir, f\"dummy_{idx}.jpg\")\n        print(\"Добавлены заглушки вместо реальных файлов для отладки.\")\n    else:\n        test_df = test_df[valid_rows].copy()  # Используем .copy() для избежания предупреждений\n    \n    print(f\"Размер тестового датасета после фильтрации: {len(test_df)}\")\n    \n    # Трансформации для тестового датасета\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    \n    test_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    \n    # Создаем датасет\n    test_dataset = ProductDataset(test_df, test_data_dir, transform=test_transform, is_test=True)\n    \n    # Создаем DataLoader\n    g = torch.Generator()\n    g.manual_seed(seed)\n    \n    num_workers = min(4, os.cpu_count() or 4)\n    \n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=64,\n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True,\n        worker_init_fn=lambda worker_id: random.seed(seed + worker_id),\n        generator=g\n    )\n    \n    # Делаем предсказания\n    predictions_df = predict(model, test_loader, seed=seed, use_transliteration=True)\n    \n    return predictions_df","metadata":{"_uuid":"95314535-f6f4-45f2-b12f-4708008f54a7","_cell_guid":"2fa5c3a5-7a4e-42cb-abfe-0b9b07c3065b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-14T02:21:37.901420Z","iopub.execute_input":"2025-03-14T02:21:37.901643Z","iopub.status.idle":"2025-03-14T02:21:37.912980Z","shell.execute_reply.started":"2025-03-14T02:21:37.901625Z","shell.execute_reply":"2025-03-14T02:21:37.912212Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"\n    Set all random seeds for reproducibility.\n    \n    Args:\n        seed (int): Seed value to use for all random number generators\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n    \n    # Make operations deterministic\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \n    # Set environment variable for Python hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n    print(f\"All random seeds set to {seed} for reproducibility\")","metadata":{"_uuid":"f9665ed0-38e6-484b-a3a4-79da52b07c9f","_cell_guid":"5e8d08ce-1bd0-4d9e-a4f1-9c55cca96a26","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-14T02:21:38.049209Z","iopub.execute_input":"2025-03-14T02:21:38.049451Z","iopub.status.idle":"2025-03-14T02:21:38.054079Z","shell.execute_reply.started":"2025-03-14T02:21:38.049432Z","shell.execute_reply":"2025-03-14T02:21:38.053317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    # Set random seeds for reproducibility\n    set_seed(42)\n    \n    # Устанавливаем все необходимые настройки для максимальной производительности\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n    \n    print(\"Запуск предсказания на тестовом датасете...\")\n    \n    # Загружаем тестовый датасет\n    test_df = pd.read_csv(TEST_CSV)\n    print(f\"Исходный размер тестового датасета: {len(test_df)}\")\n    \n    # Путь к модели\n    model_path = \"/kaggle/input/macro_/pytorch/default/1/macro_weights.pth\"\n    \n    # Делаем предсказания\n    predictions_df = predict_test_dataset(test_df, model_path)\n    \n    # Сохраняем результаты\n    predictions_df.to_csv('submission.csv', index=False)\n    print(\"Готово! Результаты сохранены в submission.csv\")","metadata":{"_uuid":"2e8f4ee7-fad2-440d-936e-272445a8cf43","_cell_guid":"70e8d5c5-51f3-48ee-97f5-ae729bdf4fee","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-14T02:15:06.486016Z","iopub.execute_input":"2025-03-14T02:15:06.486344Z","iopub.status.idle":"2025-03-14T02:15:06.491082Z","shell.execute_reply.started":"2025-03-14T02:15:06.486317Z","shell.execute_reply":"2025-03-14T02:15:06.490206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"_uuid":"def904d8-c482-406e-b5ff-b18e905aba26","_cell_guid":"7ccea21c-246c-4c55-bca5-2afdbd488a98","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-14T02:15:06.618939Z","iopub.execute_input":"2025-03-14T02:15:06.619276Z","iopub.status.idle":"2025-03-14T02:16:17.060819Z","shell.execute_reply.started":"2025-03-14T02:15:06.619253Z","shell.execute_reply":"2025-03-14T02:16:17.059801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"f4941cef-b522-4d97-ba3d-c8ce333d3ab3","_cell_guid":"57abecae-5dc2-4c9c-ba27-13bd5c46ad23","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"7b1df309-1591-40a2-997a-2dc456f31481","_cell_guid":"89e9b14b-d20c-46d0-8d31-c2bb20dc020f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"419ab0c6-5024-464d-b59c-1683e84de23c","_cell_guid":"08c73fe8-59ba-4cfa-b3d3-bd23545b387c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"ebe8d130-73b9-472e-a699-98c23ad0a8ff","_cell_guid":"4a6a0804-8bba-4aad-823b-19e998aab52e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"8ca40d84-b4bc-4444-b0ba-0ffa6ac758bc","_cell_guid":"ba1b9d48-aeab-402c-a524-6635cdf1b21e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"ae074141-59f5-46df-82b6-46f99c7a3696","_cell_guid":"5d902a33-1776-4e5c-9936-c137b5795c44","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"4edc61f9-cafe-41b4-96fb-c252ffcb3171","_cell_guid":"a364bf1d-e705-490b-8a1e-c75197ffc5ae","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"9a212d67-f859-4db8-a17a-de35b4015937","_cell_guid":"1a852693-0f7d-4414-a910-75c766fb6b2d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}