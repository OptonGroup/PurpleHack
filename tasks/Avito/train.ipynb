{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10962139,"sourceType":"datasetVersion","datasetId":6820041}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport torchvision.transforms.functional as F\nimport random\ntry:\n    import timm \nexcept ImportError:\n    print(\"Устанавливаем библиотеку timm...\")\n    import subprocess\n    subprocess.check_call([\"pip\", \"install\", \"timm\"])\n    import timm\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\nfrom tqdm import tqdm\nimport copy\nimport time\nimport timm","metadata":{"_uuid":"b16b6b71-3141-47d2-a303-8d49c5c9cb20","_cell_guid":"d709786e-1570-41d6-b38d-7ec4270ca55a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:44.829905Z","iopub.execute_input":"2025-03-13T17:16:44.830208Z","iopub.status.idle":"2025-03-13T17:16:56.18Z","shell.execute_reply.started":"2025-03-13T17:16:44.830173Z","shell.execute_reply":"2025-03-13T17:16:56.179332Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\nDATA_DIR = '/kaggle/input/colors/dataset_colors'\nTRAIN_DATA_DIR = '/kaggle/input/colors/dataset_colors/train_data'\nTEST_DATA_DIR = '/kaggle/input/colors/dataset_colors/test_data'\nTRAIN_CSV = '/kaggle/input/colors/dataset_colors/train_data.csv'\nTEST_CSV = '/kaggle/input/colors/dataset_colors/test_data.csv'","metadata":{"_uuid":"aac237fd-3b85-477d-9565-59460906fdd7","_cell_guid":"f9d41f33-36df-4b97-a388-83ac9b25dab6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.18074Z","iopub.execute_input":"2025-03-13T17:16:56.181123Z","iopub.status.idle":"2025-03-13T17:16:56.184879Z","shell.execute_reply.started":"2025-03-13T17:16:56.181102Z","shell.execute_reply":"2025-03-13T17:16:56.184016Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRANSLIT_TO_RU = {\n    'bezhevyi': 'бежевый',\n    'belyi': 'белый',\n    'biryuzovyi': 'бирюзовый',\n    'bordovyi': 'бордовый',\n    'goluboi': 'голубой',\n    'zheltyi': 'желтый',\n    'zelenyi': 'зеленый',\n    'zolotoi': 'золотой',\n    'korichnevyi': 'коричневый',\n    'krasnyi': 'красный',\n    'oranzhevyi': 'оранжевый',\n    'raznocvetnyi': 'разноцветный',\n    'rozovyi': 'розовый',\n    'serebristyi': 'серебряный',\n    'seryi': 'серый',\n    'sinii': 'синий',\n    'fioletovyi': 'фиолетовый',\n    'chernyi': 'черный'\n}","metadata":{"_uuid":"38a67564-9c3a-49b7-9a2e-da3ddf769ad9","_cell_guid":"19716ac4-1427-46de-851a-f04ce766e8ed","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.185661Z","iopub.execute_input":"2025-03-13T17:16:56.185965Z","iopub.status.idle":"2025-03-13T17:16:56.197099Z","shell.execute_reply.started":"2025-03-13T17:16:56.185936Z","shell.execute_reply":"2025-03-13T17:16:56.196262Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Маппинг цветов\nCOLORS = {\n    'бежевый': 'beige',\n    'белый': 'white',\n    'бирюзовый': 'turquoise',\n    'бордовый': 'burgundy',\n    'голубой': 'blue',\n    'желтый': 'yellow',\n    'зеленый': 'green',\n    'золотой': 'gold',\n    'коричневый': 'brown',\n    'красный': 'red',\n    'оранжевый': 'orange',\n    'разноцветный': 'variegated',\n    'розовый': 'pink',\n    'серебряный': 'silver',\n    'серый': 'gray',\n    'синий': 'blue',\n    'фиолетовый': 'purple',\n    'черный': 'black'\n}\n\n# Создаем обратный словарь для получения индекса по цвету\nCOLOR_INDICES = {c: i for i, c in enumerate(COLORS.keys())}\n\nCATEGORIES = ['одежда для девочек', 'столы', 'стулья', 'сумки']","metadata":{"_uuid":"22c3d099-79de-4976-a5b6-28cf4b158c44","_cell_guid":"0ea61e29-967d-4264-b537-ee234c106c69","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.198958Z","iopub.execute_input":"2025-03-13T17:16:56.199179Z","iopub.status.idle":"2025-03-13T17:16:56.20709Z","shell.execute_reply.started":"2025-03-13T17:16:56.199159Z","shell.execute_reply":"2025-03-13T17:16:56.206359Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ProductDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, is_test=False):\n        self.df = df.reset_index(drop=True)  # Сбрасываем индексы после фильтрации\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.category_to_idx = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n        self.color_to_idx = {color: idx for idx, color in enumerate(COLORS.keys())}\n        \n        # Проверяем все пути к изображениям заранее\n        self.valid_indices = []\n        for idx in range(len(df)):\n            img_path = os.path.join(self.img_dir, f\"{df.iloc[idx]['id']}.jpg\")\n            if os.path.exists(img_path):\n                self.valid_indices.append(idx)\n        \n        if len(self.valid_indices) == 0:\n            raise ValueError(f\"Не найдено ни одного изображения в директории {img_dir}\")\n        \n        print(f\"Найдено {len(self.valid_indices)} валидных изображений из {len(df)}\")\n        \n    def __len__(self):\n        return len(self.valid_indices)\n    \n    def __getitem__(self, idx):\n        real_idx = self.valid_indices[idx]\n        img_id = self.df.iloc[real_idx]['id']\n        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n        except Exception as e:\n            print(f\"Ошибка при загрузке изображения {img_path}: {str(e)}\")\n            raise\n        \n        if self.transform:\n            try:\n                image = self.transform(image)\n            except Exception as e:\n                print(f\"Ошибка при применении трансформации к {img_path}: {str(e)}\")\n                raise\n            \n        category = self.category_to_idx[self.df.iloc[real_idx]['category']]\n        \n        if not self.is_test:\n            color_translit = self.df.iloc[real_idx]['target']\n            color_ru = TRANSLIT_TO_RU[color_translit]\n            color = self.color_to_idx[color_ru]\n            return image, category, color\n        \n        return image, category, img_id","metadata":{"_uuid":"a392bea6-2900-4010-a4dc-44f4a806868f","_cell_guid":"2382da48-58df-4823-a9e1-071a68c6c8ba","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.20847Z","iopub.execute_input":"2025-03-13T17:16:56.208682Z","iopub.status.idle":"2025-03-13T17:16:56.219985Z","shell.execute_reply.started":"2025-03-13T17:16:56.208662Z","shell.execute_reply":"2025-03-13T17:16:56.219257Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ColorClassifier(nn.Module):\n    def __init__(self, num_colors, num_categories):\n        super().__init__()\n        # Используем более легкий и быстрый вариант ViT\n        self.backbone = timm.create_model(\n            'beitv2_large_patch16_224', \n            pretrained=True, \n            num_classes=0,  # Без верхнего слоя классификации\n        )\n        \n        # Фиксируем большую часть весов для ускорения обучения\n        for param in list(self.backbone.parameters())[:-30]:\n            param.requires_grad = False\n            \n        # Расширение для быстрой инференции с помощью кэширования\n        self.backbone.reset_classifier(0)\n        \n        # Размерность характеристик модели\n        self.feature_dim = self.backbone.embed_dim  # Для vit_tiny это 192\n        \n        # Эмбеддинг категории\n        self.category_embedding = nn.Embedding(num_categories, 32)\n        \n        # Классификационная голова\n        self.classifier = nn.Sequential(\n            nn.Linear(self.feature_dim + 32, 256),  # Меньше параметров для ускорения\n            nn.ReLU(),\n            nn.Dropout(0.2),  # Меньше дропаут для более быстрой сходимости\n            nn.Linear(256, num_colors)\n        )\n        \n        # Для оптимизации torch.jit\n        self.example_input = torch.zeros(1, 3, 224, 224)\n        self.example_category = torch.LongTensor([0])\n        \n    def forward(self, x, category):\n        features = self.backbone(x)\n        \n        category_emb = self.category_embedding(category)\n        combined = torch.cat([features, category_emb], dim=1)\n        \n        return self.classifier(combined)\n\n    def optimize_for_inference(self, device):\n        \"\"\"Оптимизирует модель для быстрой инференции\"\"\"\n        self.eval()\n        # Использование TorchScript для оптимизации\n        return torch.jit.trace((self.example_input.to(device), self.example_category.to(device)), self)","metadata":{"_uuid":"66aa56e1-b1c0-4ff3-8463-705181374b95","_cell_guid":"6e3b51a8-eda9-405a-bf13-4f8f0547aee6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.220722Z","iopub.execute_input":"2025-03-13T17:16:56.220956Z","iopub.status.idle":"2025-03-13T17:16:56.23048Z","shell.execute_reply.started":"2025-03-13T17:16:56.220937Z","shell.execute_reply":"2025-03-13T17:16:56.229658Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport copy\n\n# Импортируем метрики из scikit-learn\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\n\ndef train_model(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    scheduler,\n    num_epochs=400,\n    seed=42\n):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    scaler = torch.cuda.amp.GradScaler()  # Для автоматического масштабирования градиентов при mixed precision\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_f1 = 0.0\n    \n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'val_acc': [],\n        'val_f1': []\n    }\n    \n    for epoch in range(num_epochs):\n        # Устанавливаем сид для каждой эпохи для воспроизводимости\n        # Используем разные сиды для разных эпох, но детерминированно\n        epoch_seed = seed + epoch\n        torch.manual_seed(epoch_seed)\n        np.random.seed(epoch_seed)\n        random.seed(epoch_seed)\n        \n        print(f'Эпоха {epoch+1}/{num_epochs}')\n        print('-' * 10)\n        \n        # Обучение\n        model.train()\n        running_loss = 0.0\n        \n        train_batches = tqdm(train_loader, desc=\"Обучение\")\n        \n        for inputs, categories, colors in train_batches:\n            inputs = inputs.to(device)\n            categories = categories.to(device)\n            colors = colors.to(device)\n            \n            # Обнуляем градиенты\n            optimizer.zero_grad()\n            \n            # Прямой проход с автоматическим приведением к float16\n            with torch.cuda.amp.autocast():\n                outputs = model(inputs, categories)\n                loss = criterion(outputs, colors)\n            \n            # Обратное распространение с масштабированием для предотвращения исчезновения градиентов\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += loss.item() * inputs.size(0)\n            \n            # Обновляем статус прогресс-бара\n            train_batches.set_postfix(loss=loss.item())\n        \n        epoch_loss = running_loss / len(train_loader.dataset)\n        history['train_loss'].append(epoch_loss)\n        \n        print(f'Потери при обучении: {epoch_loss:.4f}')\n        \n        # Валидация\n        model.eval()\n        val_loss = 0.0\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for inputs, categories, colors in tqdm(val_loader, desc=\"Валидация\"):\n                inputs = inputs.to(device)\n                categories = categories.to(device)\n                colors = colors.to(device)\n                \n                # Используем mixed precision и для инференса\n                with torch.cuda.amp.autocast():\n                    outputs = model(inputs, categories)\n                    loss = criterion(outputs, colors)\n                \n                val_loss += loss.item() * inputs.size(0)\n                \n                _, preds = torch.max(outputs, 1)\n                \n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(colors.cpu().numpy())\n        \n        val_loss = val_loss / len(val_loader.dataset)\n        \n        # Вычисляем метрики\n        val_acc = accuracy_score(all_labels, all_preds)\n        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n        \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        history['val_f1'].append(f1)\n        \n        print(f'Потери при валидации: {val_loss:.4f}')\n        print(f'Точность: {val_acc:.4f}')\n        print(f'F1-мера: {f1:.4f}')\n        print(f'Precision: {precision:.4f}')\n        print(f'Recall: {recall:.4f}')\n        \n        # Save the best model based on F1 score\n        if f1 > best_f1:  # Change best_acc to best_f1 for clarity\n            best_f1 = f1  # Update best_acc to best_f1\n            best_model_wts = copy.deepcopy(model.state_dict())\n            # Save the intermediate best model\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'num_colors': len(COLORS),\n                'num_categories': len(CATEGORIES)\n            }, 'vit_color_classifier.pth')\n            print(\"Сохранена новая лучшая модель по F1!\")\n        \n        # Шаг планировщика скорости обучения\n        scheduler.step()\n        \n        print()\n    \n    print(f'Лучшая точность при валидации: {best_f1:.4f}')\n    \n    # Возвращаем лучшие веса модели и историю обучения\n    return best_model_wts, history","metadata":{"_uuid":"46756494-0d54-459e-844a-2c4aa2922e0c","_cell_guid":"aa9714f2-0166-4ee9-b0a9-3cf23bdf651f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.231295Z","iopub.execute_input":"2025-03-13T17:16:56.231581Z","iopub.status.idle":"2025-03-13T17:16:56.24574Z","shell.execute_reply.started":"2025-03-13T17:16:56.231557Z","shell.execute_reply":"2025-03-13T17:16:56.244995Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(model_path):\n    \"\"\"\n    Загружает ранее обученную модель из указанного пути.\n    Если модель была сохранена как TorchScript, загрузит её как таковую.\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Проверяем формат сохраненной модели\n    try:\n        # Пробуем загрузить как TorchScript модель\n        model = torch.jit.load(model_path, map_location=device)\n        print(\"Загружена оптимизированная TorchScript модель\")\n        return model\n    except:\n        # Загружаем как обычную модель\n        print(\"Загружаем модель из стандартных весов...\")\n        model = ColorClassifier(len(COLORS), len(CATEGORIES))\n        \n        checkpoint = torch.load(model_path, map_location=device)\n        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n            model.load_state_dict(checkpoint['model_state_dict'])\n        else:\n            model.load_state_dict(checkpoint)\n        \n        # Установка модели в режим оценки (инференса)\n        model.eval()\n        \n        # Если мы на GPU, оптимизируем модель для инференса\n        if device.type == 'cuda' and hasattr(model, 'optimize_for_inference'):\n            try:\n                print(\"Оптимизация модели для быстрого инференса...\")\n                model = model.optimize_for_inference(device)\n                # Сохраняем оптимизированную версию\n                optimized_path = model_path.replace('.pth', '_optimized.pth')\n                torch.jit.save(model, optimized_path)\n                print(f\"Оптимизированная модель сохранена как {optimized_path}\")\n            except Exception as e:\n                print(f\"Не удалось оптимизировать модель: {e}\")\n        \n        return model","metadata":{"_uuid":"fa5d1135-55b6-4963-8d5b-243114630cd4","_cell_guid":"eb1bd393-ae83-4abe-8cb9-55fc257adf84","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.24661Z","iopub.execute_input":"2025-03-13T17:16:56.24687Z","iopub.status.idle":"2025-03-13T17:16:56.261779Z","shell.execute_reply.started":"2025-03-13T17:16:56.246842Z","shell.execute_reply":"2025-03-13T17:16:56.261172Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(model, test_loader, seed=42):\n    # Устанавливаем сид для воспроизводимости\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Используется устройство: {device}\")\n    \n    model = model.to(device)\n    model.eval()\n    \n    # Оптимизация модели для инференции\n    if hasattr(model, 'optimize_for_inference') and device.type == 'cuda':\n        try:\n            model = model.optimize_for_inference(device)\n        except Exception as e:\n            print(f\"Не удалось оптимизировать модель: {e}\")\n    \n    predictions = []\n    ids = []\n    \n    color_list = list(COLORS.keys())\n    \n    # Замер времени на один батч\n    batch_times = []\n    \n    with torch.no_grad():\n        for images, categories, img_ids in test_loader:\n            images = images.to(device)\n            categories = categories.to(device)\n            \n            # Замер времени\n            start_time = time.time()\n            outputs = model(images, categories)\n            end_time = time.time()\n            \n            inference_time = (end_time - start_time) * 1000  # мс\n            batch_times.append(inference_time / len(images))  # время на один образец\n            \n            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n            \n            for img_id, prob in zip(img_ids, probs):\n                pred_dict = {color: float(p) for color, p in zip(color_list, prob)}\n                pred_color = color_list[np.argmax(prob)]\n                \n                predictions.append({\n                    'id': img_id,\n                    'predict_proba': json.dumps(pred_dict),\n                    'predict_color': pred_color\n                })\n                \n    # Вывод среднего времени инференции\n    if batch_times:\n        avg_time = sum(batch_times) / len(batch_times)\n        print(f\"Среднее время инференции на одно изображение: {avg_time:.2f} мс\")\n    \n    # Создаем DataFrame с предсказаниями\n    predictions_df = pd.DataFrame(predictions)\n    return predictions_df","metadata":{"_uuid":"ec9649c6-4240-4c1a-a19c-92f06425bbe6","_cell_guid":"bc9622cc-c060-487e-af61-445e0a3691c4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.262558Z","iopub.execute_input":"2025-03-13T17:16:56.262784Z","iopub.status.idle":"2025-03-13T17:16:56.27811Z","shell.execute_reply.started":"2025-03-13T17:16:56.262765Z","shell.execute_reply":"2025-03-13T17:16:56.277447Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def benchmark_inference(model, image_size=(224, 224), num_runs=100, batch_size=1):\n    \"\"\"\n    Тестирует производительность модели, измеряя время инференса.\n    \n    Args:\n        model: Модель для тестирования\n        image_size: Размер входного изображения (высота, ширина)\n        num_runs: Количество прогонов для усреднения результатов\n        batch_size: Размер батча для тестирования\n        \n    Returns:\n        float: Среднее время инференса в миллисекундах на один образец\n    \"\"\"\n    device = next(model.parameters()).device\n    \n    # Устанавливаем сид для воспроизводимости генерации тестовых данных\n    torch.manual_seed(42)\n    \n    # Создаем случайные тензоры для тестирования\n    dummy_input = torch.randn(batch_size, 3, *image_size, device=device)\n    dummy_category = torch.zeros(batch_size, dtype=torch.long, device=device)\n    \n    # Прогрев модели\n    print(\"Прогрев модели...\")\n    with torch.no_grad():\n        for _ in range(10):\n            _ = model(dummy_input, dummy_category)\n    \n    # Синхронизация GPU перед тестами\n    if device.type == 'cuda':\n        torch.cuda.synchronize()\n    \n    # Измерение времени\n    print(f\"Запуск бенчмарка ({num_runs} прогонов)...\")\n    times = []\n    \n    with torch.no_grad():\n        for _ in range(num_runs):\n            if device.type == 'cuda':\n                torch.cuda.synchronize()\n            \n            start_time = time.time()\n            _ = model(dummy_input, dummy_category)\n            \n            if device.type == 'cuda':\n                torch.cuda.synchronize()\n            \n            end_time = time.time()\n            inference_time = (end_time - start_time) * 1000  # мс\n            times.append(inference_time / batch_size)  # время на один образец\n    \n    # Вычисляем статистики\n    avg_time = sum(times) / len(times)\n    min_time = min(times)\n    max_time = max(times)\n    p95_time = sorted(times)[int(len(times) * 0.95)]\n    \n    print(f\"Результаты бенчмарка:\")\n    print(f\"  Среднее время инференса: {avg_time:.2f} мс\")\n    print(f\"  Минимальное время: {min_time:.2f} мс\")\n    print(f\"  Максимальное время: {max_time:.2f} мс\")\n    print(f\"  95-й перцентиль: {p95_time:.2f} мс\")\n    \n    return avg_time\n\ndef set_seed(seed=42):\n    \"\"\"\n    Set all random seeds for reproducibility.\n    \n    Args:\n        seed (int): Seed value to use for all random number generators\n        \n    This function sets seeds for:\n    - Python's random module\n    - NumPy\n    - PyTorch (both CPU and CUDA)\n    - CUDA operations\n    \n    It also configures PyTorch to use deterministic algorithms where possible.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n    \n    # Make operations deterministic\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \n    # Set environment variable for Python hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n    print(f\"All random seeds set to {seed} for reproducibility\")\n\ndef main():\n    # Set random seeds for reproducibility\n    set_seed(42)\n    \n    # Устанавливаем все необходимые настройки для максимальной производительности\n    # Note: Setting cudnn.benchmark=True can improve performance but reduces reproducibility\n    # We'll comment this out since we prioritize reproducibility\n    # torch.backends.cudnn.benchmark = True\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n    \n    # Проверяем наличие библиотеки timm\n    try:\n        import timm\n        print(f\"Версия timm: {timm.__version__}\")\n    except ImportError:\n        print(\"Устанавливаем библиотеку timm...\")\n        import subprocess\n        subprocess.check_call([\"pip\", \"install\", \"timm\"])\n        import timm\n        print(f\"Установлена библиотека timm версии {timm.__version__}\")\n    \n    required_paths = [\n        TRAIN_CSV,\n        TEST_CSV,\n        TRAIN_DATA_DIR,\n        TEST_DATA_DIR\n    ]\n    \n    for path in required_paths:\n        if not os.path.exists(path):\n            raise FileNotFoundError(f\"Не найден путь: {path}\")\n            \n    print(\"Все необходимые файлы и директории найдены\")\n    \n    train_df = pd.read_csv(TRAIN_CSV)\n    test_df = pd.read_csv(TEST_CSV)\n    \n    print(f\"Исходный размер тренировочного датасета: {len(train_df)}\")\n    print(f\"Исходный размер тестового датасета: {len(test_df)}\")\n    \n    def check_image_exists(row, data_dir):\n        img_path = os.path.join(data_dir, f\"{row['id']}.jpg\")\n        return os.path.exists(img_path)\n    \n    # Фильтруем только существующие изображения\n    train_df = train_df[train_df.apply(lambda row: check_image_exists(row, TRAIN_DATA_DIR), axis=1)]\n    test_df = test_df[test_df.apply(lambda row: check_image_exists(row, TEST_DATA_DIR), axis=1)]\n    \n    print(f\"Размер тренировочного датасета после фильтрации: {len(train_df)}\")\n    print(f\"Размер тестового датасета после фильтрации: {len(test_df)}\")\n    \n    train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n    \n    print(f\"Размер обучающего датасета: {len(train_df)}\")\n    print(f\"Размер валидационного датасета: {len(val_df)}\")\n    \n    # Оптимизированные трансформации для ViT\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    \n    # Обучающие трансформации с фиксированными сидами для воспроизводимости\n    train_transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Сразу переходим к целевому размеру для ускорения \n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomRotation(10, fill=0, interpolation=transforms.InterpolationMode.BILINEAR),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    \n    # Облегченные трансформации для тестирования и валидации\n    test_transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Целевой размер для ViT\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n    \n    # Создаем датасеты\n    train_dataset = ProductDataset(train_df, TRAIN_DATA_DIR, transform=train_transform)\n    val_dataset = ProductDataset(val_df, TRAIN_DATA_DIR, transform=test_transform)\n    test_dataset = ProductDataset(test_df, TEST_DATA_DIR, transform=test_transform, is_test=True)\n    \n    # Функция инициализации воркеров для обеспечения воспроизводимости\n    def seed_worker(worker_id):\n        worker_seed = 42 + worker_id\n        np.random.seed(worker_seed)\n        random.seed(worker_seed)\n        \n    # Генератор для DataLoader\n    g = torch.Generator()\n    g.manual_seed(42)\n    \n    # Оптимизируем загрузчики данных\n    # Используем pin_memory=True для ускорения передачи данных на GPU\n    # Увеличиваем num_workers для параллельной загрузки данных\n    num_workers = min(4, os.cpu_count() or 4)  # Разумное количество потоков\n    \n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=32, \n        shuffle=True, \n        num_workers=num_workers,\n        pin_memory=True,\n        worker_init_fn=seed_worker,\n        generator=g\n    )\n    \n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=64,  # Больший размер батча для валидации\n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True,\n        worker_init_fn=seed_worker,\n        generator=g\n    )\n    \n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=64,  # Используем больший размер батча для ускорения инференса\n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True,\n        worker_init_fn=seed_worker,\n        generator=g\n    )\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Используется устройство: {device}\")\n    \n    torch.cuda.empty_cache()  # Очищаем память GPU\n    \n    model_path = \"/kaggle/input/macro_/pytorch/default/1/macro_weights.pth\"\n    \n    if os.path.exists(model_path):\n        print(\"Загружаем существующую модель...\")\n        model = load_model(model_path)\n        model = model.to(device)\n    else:\n        print(\"Начинаем обучение новой модели...\")\n        # Устанавливаем сид перед инициализацией модели для воспроизводимости весов\n        torch.manual_seed(42)\n        torch.cuda.manual_seed(42)\n        # Если используется timm, установим его сид тоже\n        try:\n            import timm\n            timm.random.set_random_seed(42)\n        except (ImportError, AttributeError):\n            pass\n            \n        model = ColorClassifier(len(COLORS), len(CATEGORIES))\n        model = model.to(device)\n        \n        criterion = nn.CrossEntropyLoss()\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n        \n        # --- ВАЖНО: теперь train_model возвращает два значения ---\n        best_model_state, history = train_model(\n            model, train_loader, val_loader, criterion, optimizer, scheduler, seed=42\n        )\n        model.load_state_dict(best_model_state)\n    \n    # Выполняем прогрев модели для оптимизации CUDA графов\n    if device.type == 'cuda':\n        print(\"Оптимизация модели для инференса...\")\n        # Устанавливаем сид для воспроизводимости генерации тестовых данных\n        torch.manual_seed(42)\n        dummy_input = torch.randn(1, 3, 224, 224, device=device)\n        dummy_category = torch.tensor([0], device=device)\n        with torch.no_grad():\n            for _ in range(10):  # Прогрев\n                _ = model(dummy_input, dummy_category)\n    \n    # Запускаем бенчмарк для измерения производительности\n    print(\"\\nЗапуск бенчмарка производительности...\")\n    avg_time = benchmark_inference(model, image_size=(224, 224), num_runs=100)\n    \n    if avg_time <= 200:\n        print(f\"✅ Модель соответствует требованию по скорости (< 200 мс): {avg_time:.2f} мс\")\n    else:\n        print(f\"❌ Модель НЕ соответствует требованию по скорости (< 200 мс): {avg_time:.2f} мс\")\n    \n    print(\"\\nДелаем предсказания...\")\n    predictions_df = predict(model, test_loader, seed=42)\n    predictions_df.to_csv('submission.csv', index=False)\n    print(\"Готово! Результаты сохранены в submission.csv\")","metadata":{"_uuid":"b1a9467f-b3ce-4904-baa8-513ebfebfd4f","_cell_guid":"5a971a55-6ec5-4215-8d9e-e6727dd4603b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.279012Z","iopub.execute_input":"2025-03-13T17:16:56.279241Z","iopub.status.idle":"2025-03-13T17:16:56.298078Z","shell.execute_reply.started":"2025-03-13T17:16:56.279222Z","shell.execute_reply":"2025-03-13T17:16:56.29739Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"_uuid":"f8154523-2833-45b2-91bd-614aed82ccd8","_cell_guid":"276f5995-f9d3-4474-af8b-9651c3026a1c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T17:16:56.298969Z","iopub.execute_input":"2025-03-13T17:16:56.299276Z","execution_failed":"2025-03-13T17:31:54.818Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"feef725d-89a5-4f13-89e4-bdf16fac3649","_cell_guid":"1df38c69-6ee8-422c-b87b-73bc3e700528","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"1ca14d2f-b58b-4bc4-9065-bdaa7454adb8","_cell_guid":"25e722b5-5e16-468f-a414-b018aa126a89","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"0f32dfb8-1ca3-4fb3-a6a0-5e0f1020e101","_cell_guid":"97c9dde6-b4f7-46d9-8545-3cfc55cf98e9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"b0e89c3a-5c8b-4aac-86c6-fe1226151993","_cell_guid":"45d6a4c6-a32d-45a0-80f2-e7ee75aaaec4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"7a22bd8d-3cde-4868-a43b-96420a32e797","_cell_guid":"cb778436-cece-4185-a577-65450604f370","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"5b613363-119e-4dda-b8d5-30125ef412cd","_cell_guid":"a6774ccc-f0df-491c-8834-56c50f616b6e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"dd3bc476-4a8e-42b1-802d-09dd5e4ee9d8","_cell_guid":"8794ffb4-5964-421f-b450-1f4d3410cf73","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"a89e3097-e67c-4a3c-a344-9a0e454e0818","_cell_guid":"8f5a7bc8-29ca-40d3-977a-d378d38bc0d3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"7b580916-7d90-4641-a85c-0ac96bfe8e86","_cell_guid":"bb458ef9-fc80-452b-814d-023aee258ef1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}